# Singl News

**The world's only unified continuous news story.**

Singl News presents a single, perpetually evolving narrative constructed from multiple real RSS news feeds. Instead of fragmenting reality into discrete articles, it recognizes that all events are interconnected threads in one continuous story.

## ğŸŒ Domains

- **Primary**: `singl.news`
- **Mirror**: `news.ainot.io`

## ğŸ¯ Concept

There is only ONE story in existence. Every news event is just a new paragraph in this ongoing, global, unified narrative. The story evolves foreverâ€”never resetting, only growing and recontextualizing what came before.

## ğŸ—ï¸ Architecture

### Backend (Python/FastAPI)
- **Framework**: FastAPI with async support
- **Database**: PostgreSQL with SQLAlchemy ORM
- **AI**: OpenAI API for story generation
- **Scheduling**: APScheduler for periodic updates
- **RSS**: Feedparser for news ingestion
- **WebSocket**: Real-time story updates

### Frontend (SvelteKit)
- **Framework**: SvelteKit with TypeScript
- **Styling**: Modern CSS with newspaper design
- **Real-time**: WebSocket client for live updates
- **Features**: Infinite scroll doomscroll experience

### Infrastructure
- **Containerization**: Docker & Docker Compose
- **Database**: PostgreSQL 16
- **Migrations**: Alembic

## ğŸš€ Quick Start

### Prerequisites

- Docker and Docker Compose
- OpenAI API key

### Installation

1. **Clone the repository**
   ```bash
   git clone <repository-url>
   cd news.ainot.io
   ```

2. **Set up environment variables**
   ```bash
   cp .env.example .env
   # Edit .env and add your OPENAI_API_KEY
   ```

3. **Start the services**
   ```bash
   docker-compose up --build
   ```

4. **Access the application**
   - Frontend: http://localhost:3000
   - Backend API: http://localhost:8000
   - API Docs: http://localhost:8000/docs

The system will automatically:
- Initialize the database
- Run migrations
- Fetch RSS feeds
- Generate the first story version
- Continue updating every N minutes (default: 30)

## ğŸ› ï¸ Development

### Backend Development

```bash
cd backend

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Set environment variables
export DATABASE_URL="postgresql+psycopg2://singl:singl@localhost:5432/singl"
export OPENAI_API_KEY="your-key-here"

# Run migrations
alembic upgrade head

# Start development server
python -m app.main
```

### Frontend Development

```bash
cd frontend

# Install dependencies
npm install

# Create .env file
cp .env.example .env

# Start development server
npm run dev
```

## ğŸ“‹ Environment Variables

### Backend

| Variable | Description | Default |
|----------|-------------|---------|
| `DATABASE_URL` | PostgreSQL connection string | `postgresql+psycopg2://singl:singl@db:5432/singl` |
| `OPENAI_API_KEY` | OpenAI API key | **Required** |
| `SINGL_MODEL_NAME` | OpenAI model to use | `gpt-4-turbo-preview` |
| `SINGL_UPDATE_MINUTES` | Minutes between story updates | `30` |
| `SINGL_CONTEXT_STEPS` | Number of recent versions for context | `10` |
| `SINGL_FEEDS` | Comma-separated RSS feed URLs | Multiple defaults |
| `SINGL_LOG_LEVEL` | Logging level | `INFO` |

### Frontend

| Variable | Description | Default |
|----------|-------------|---------|
| `VITE_API_URL` | Backend API URL | `http://localhost:8000` |
| `VITE_WS_URL` | WebSocket URL | `ws://localhost:8000/ws/story` |

## ğŸ“¡ API Endpoints

### REST API

- `GET /api/story/current` - Get the latest story version
- `GET /api/story/history?limit=20&offset=0` - Get paginated story history
- `GET /api/story/{id}` - Get specific story version
- `GET /api/meta` - Get service metadata
- `GET /api/health` - Health check
- `GET /docs` - Interactive API documentation

### WebSocket

- `ws://localhost:8000/ws/story` - Real-time story updates

## ğŸ—„ï¸ Database Schema

### StoryVersion
- `id` - Primary key
- `created_at` - Timestamp (indexed)
- `full_text` - Complete story text
- `summary` - Brief summary
- `context_summary` - Compressed narrative context
- `sources_snapshot` - JSON of contributing feed items
- `token_stats` - JSON of OpenAI usage statistics

### FeedItem
- `id` - Primary key
- `feed_url` - Source feed URL
- `feed_name` - Source name
- `title` - Item title
- `summary` - Item description
- `link` - Item URL
- `published_at` - Publication timestamp
- `fetched_at` - Ingestion timestamp
- `content_hash` - Deduplication hash (unique)
- `raw` - JSON of raw feed data

## ğŸ§ª Testing

### Backend Tests

```bash
cd backend
pytest
```

### Frontend Tests

```bash
cd frontend
npm run test
```

## ğŸ¨ Design Philosophy

### In-Character UI
- **No meta-commentary**: Never mentions AI, fiction, or parody
- **Serious tone**: Confident, newspaper-like presentation
- **Minimalist design**: Clean typography, single-column layout
- **Continuous narrative**: History presented as scrollable extensions

### Story Evolution
- **Never resets**: Each update extends the existing narrative
- **Context preservation**: Uses rolling summaries to maintain continuity
- **Seamless integration**: New events woven into established storylines
- **Infinite timeline**: Complete history preserved in database

## ğŸ“ Project Structure

```
news.ainot.io/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ alembic/              # Database migrations
â”‚   â”‚   â””â”€â”€ versions/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ main.py          # FastAPI app
â”‚   â”‚   â”œâ”€â”€ config.py        # Settings
â”‚   â”‚   â”œâ”€â”€ database.py      # DB setup
â”‚   â”‚   â”œâ”€â”€ models.py        # SQLAlchemy models
â”‚   â”‚   â”œâ”€â”€ schemas.py       # Pydantic schemas
â”‚   â”‚   â”œâ”€â”€ api.py           # REST endpoints
â”‚   â”‚   â”œâ”€â”€ ws.py            # WebSocket support
â”‚   â”‚   â”œâ”€â”€ scheduler.py     # Background jobs
â”‚   â”‚   â”œâ”€â”€ story_service.py # Business logic
â”‚   â”‚   â”œâ”€â”€ rss_client.py    # Feed fetching
â”‚   â”‚   â””â”€â”€ openai_client.py # AI integration
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ Dockerfile
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ lib/
â”‚   â”‚   â”‚   â”œâ”€â”€ api.ts       # API client
â”‚   â”‚   â”‚   â”œâ”€â”€ ws.ts        # WebSocket client
â”‚   â”‚   â”‚   â””â”€â”€ config.ts    # Configuration
â”‚   â”‚   â””â”€â”€ routes/
â”‚   â”‚       â”œâ”€â”€ +layout.svelte
â”‚   â”‚       â”œâ”€â”€ +page.svelte          # Home (live story)
â”‚   â”‚       â”œâ”€â”€ history/+page.svelte  # Archive
â”‚   â”‚       â”œâ”€â”€ story/[id]/+page.svelte  # Story detail
â”‚   â”‚       â””â”€â”€ about/+page.svelte    # About page
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ Dockerfile
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ .env.example
â””â”€â”€ README.md
```

## ğŸ”„ How It Works

### Story Generation Cycle

1. **RSS Ingestion**
   - Fetches configured RSS feeds
   - Parses and normalizes items
   - Deduplicates and stores in database

2. **Context Building**
   - Retrieves recent story versions
   - Compresses older versions into summary
   - Gathers new feed items since last update

3. **AI Generation**
   - Sends context + recent excerpts + new events to OpenAI
   - Model generates continuation that:
     - Maintains narrative continuity
     - Integrates new developments
     - Preserves established characters/themes
     - Never resets or starts over

4. **Storage & Broadcast**
   - Saves new story version to database
   - Generates context summary for next iteration
   - Broadcasts to all connected WebSocket clients

5. **Repeat**
   - Cycle runs every N minutes (configurable)
   - Story grows perpetually

## ğŸ­ Character Constraints

### Public-Facing (UI/Website)
- Maintains in-universe character as legitimate news organization
- No admission of being AI-generated or fictional
- Professional, confident tone throughout
- Vague "automated editorial processes" if explanation needed

### Internal (Code/Docs)
- Can freely acknowledge it's an art/experimental project
- Technical documentation can be explicit about implementation
- Comments and internal docs explain actual functionality

## ğŸš¢ Deployment

### Production Considerations

1. **Environment Variables**: Set proper production values
2. **Database**: Use managed PostgreSQL service or proper backups
3. **API Keys**: Secure OpenAI API key management
4. **Domain**: Configure proper CORS and WebSocket origins
5. **Scaling**: Consider rate limits and token costs
6. **Monitoring**: Set up logging and error tracking
7. **SSL**: Use HTTPS and WSS in production

### Example Production Setup

```bash
# Set production environment variables
export OPENAI_API_KEY="sk-..."
export DATABASE_URL="postgresql://..."
export SINGL_WS_ORIGIN="https://singl.news,https://news.ainot.io"

# Build and deploy
docker-compose -f docker-compose.prod.yml up -d
```

## ğŸ“œ License

This project is an experimental art/technology piece exploring AI-generated continuous narrative.

## ğŸ¤ Contributing

This is an experimental project. Feel free to fork and create your own variations.

## âš ï¸ Important Notes

- **OpenAI Costs**: Running this will consume OpenAI API credits. Monitor your usage.
- **RSS Feed Limits**: Some feeds may have rate limits or restrictions.
- **Database Growth**: Story history grows indefinitely; plan storage accordingly.
- **Ethical Use**: This is clearly an experimental/art project. Don't misrepresent it as actual news.

---

**Remember**: There is only one story. Everything else is commentary.
